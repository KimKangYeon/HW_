{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "중간과제 최종본의 사본",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1IE1bzlGDrFmRAujlarptHXMeJTH5wyQb",
      "authorship_tag": "ABX9TyNxpMeVg4REXHJ2+uKxVVob",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KimKangYeon/HW_/blob/master/%EC%A4%91%EA%B0%84%EA%B3%BC%EC%A0%9C_%EC%B5%9C%EC%A2%85%EB%B3%B8%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqEJjEa-rnAc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1705de32-299f-46fe-bb60-0968dc370140"
      },
      "source": [
        "!pip install -q tensorflow-gpu==2.0.0-rc1\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
        "from tensorflow.keras import Model\n",
        "# 텐서플로어와 필요한 모듈을 임포트해주었습니다."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 380.5MB 46kB/s \n",
            "\u001b[K     |████████████████████████████████| 4.3MB 48.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 7.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 501kB 50.5MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6IniQHHrnn5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53505688-23d3-43e0-a48f-c7aea63fd8fd"
      },
      "source": [
        "# 그런 다음 mnist dataset을 로드해주었습니다.\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# multiple dimention을 추가할 때와 slice를 선택하고 새로운 dimensions을 추가할 때 편리함을 위해 train 변수와 test 변수에 a[:,:,tf.newaxis]:을 이용하여 차원을 추가해주었습니다.\n",
        "x_train = x_train[..., tf.newaxis]\n",
        "x_test = x_test[..., tf.newaxis]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWm-Hp91rt2Q"
      },
      "source": [
        "train_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    (x_train, y_train)).shuffle(5000).batch(32)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)\n",
        "# 많은 양의 데이터를 처리해야하기 때문에 tf.data api를 이용하여 복잡한 변환을 수행하였습니다. 이 과정에서 dataset을 셔플해주고 배치를 만들어주었습니다. \n",
        "# 다른 파라미터는 고정시키고 셔플 횟수와 배치 개수를 변경해보며 경향성을 파악한 후 가장 높은 정확도를 가지는 값을 찾아보았습니다. \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-o2HKikrv63"
      },
      "source": [
        "# 그런다음 model subclassing api를 사용해서 모델을 만들었습니다.\n",
        "class MyModel(Model):\n",
        "  def __init__(self):\n",
        "    super(MyModel, self).__init__()\n",
        "    self.conv1 = Conv2D(32, 3, activation='relu')\n",
        "    self.flatten = Flatten()\n",
        "    self.d1 = Dense(256, activation='relu')\n",
        "    self.d2 = Dense(128, activation='relu')\n",
        "    # self.d3 = tf.keras.layers.Dropout(0.2)\n",
        "    self.d3 = Dense(10, activation='softmax')\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.flatten(x)\n",
        "    x = self.d1(x)\n",
        "    x = self.d2(x)    \n",
        "    return self.d3(x)\n",
        "\n",
        "model = MyModel()\n",
        "# relu activation function은 Monotonic하고(단조롭고 즉, 증가만 하거나 감소만 하고) Derivative Monotonic 하기 때문에 \n",
        "# 어떤 입력 값이 커질수록 어떤 경향을 보인다로 해석 가능하고 어떤 입력 값의 기울기는 어떤 경향을 보인다로 해석 가능하다는 이점이 있어 사용하였습니다.\n",
        "# 또한 위키백과를 통해 \"Better gradient propagation: Fewer vanishing gradient problems compared to sigmoidal activation functions that saturate in both directions\"하다는\n",
        "# 사실을 알게 되어 조교님께서 예제 코드에서 사용하셨던 sigmoid 함수 대신 relu를 사용하였습니다.\n",
        "# 그리고 위키백과를 통해 추가적으로 \"Biological plausibility: One-sided, compared to the antisymmetry of tanh\"하다는 점을 이용하여 tanh 대신 relu를 사용하였습니다.\n",
        "# 입력과 출력을 모두 연결해주는 역할을 하는 Dense 레이어를 사용하였습니다. 예를 들어 입력 뉴런이 n개, 출력 뉴런이 m개있다면 총 연결선은 n*m개입니다. \n",
        "# 각 연결선은 가중치(weight)를 포함하고 있고 그 가중치가 높을수록 해당 입력 뉴런이 출력 뉴런에 미치는 영향이 크고, 낮을수록 미치는 영향이 적다는 점을 이용하여 적절한 출력뉴런의 수를 설정해주었습니다.\n",
        "# Dense 레이어는 입력 뉴런 수에 상관없이 출력 뉴런 수를 자유롭게 설정할 수 있기 때문에 출력층으로 사용하였습니다. \n",
        "# Dense(출력 뉴런의 수, 입력 뉴런의 수, 가중치 초기화 방법, activation='활성화 함수 설정') 구조를 이용하여 해당 값들을 바꿔가며 가장 높은 정확도를 가지는 값을 찾아보았습니다.\n",
        "# Dense 레이어의 첫번째 인자는 분류기에 사용되는 뉴런의 수를 뜻하기 때문에 숫자의 경우 복잡한 문제가 아니므로 적절한 수로 설정하였습니다.\n",
        "# 소프트맥스 함수는 다중 클래스 분류에서 출력층에 주로 사용하기 때문에 마지막 출력층에 넣었습니다.\n",
        "# 마지막 Dense 레이어의 뉴런의 숫자는 숫자 인식기의 경우 0에서 9까지 총 10개의 class를 구분하기 때문에 10으로 설정하였습니다.\n",
        "# 입력 뉴런과 가중치를 계산한 값을 0에서 1사이로 표현할 수 있는 활성화 함수 중에서 앞서 언급한 이유로 인해 sigmoid 함수 대신 relu 함수를 사용하였습니다.\n",
        "# 영상처리에서 사용하는 컨볼루션 연산을 이용하여 이미지의 경계선을 뽑거나 흐릿하게 만드는 과정을 처리하였습니다.\n",
        "# conv2d()를 이용하여 컨볼루션 연산을 할 크기, 필터 이미지 개수, 활성화함수를 설정해주었습니다.\n",
        "# conv2D 레이어의 첫번째 인자는 사용하는 이미지 특징의 수를 뜻하고 얼굴과 같은 복잡한 이미지의 경우 특징 숫자를 늘려주는게 좋지만 숫자의 경우 비교적 단순하기 때문에 32로 설정하였습니다.\n",
        "# Flatten()을 이용하여 Fully Connected 레이어를 만들고 다차원의 입력을 단순한 일차원으로 만들었습니다.\n",
        "# 초기 Dropout()를 추가하여 오버피팅을 방지하고자 하였는데 오히려 정확도를 떨어뜨리는 결과를 보여 주석처리하였습니다.\n",
        "# 아래의 텍스트로 파라미터들을 변화시켜가며 최고의 정확도를 보이는 값을 찾아가는 과정을 첨부하였습니다. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXX8CESaWXyI"
      },
      "source": [
        "셔플횟수 /  \tbatch size /\t트레이닝정확도(%)\t/ 테스트정확도(%)\t/ 에포크 수\t\t\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "10000\t/ 32 /\t98.59\t / 98.12999\t/ 5\t\t   (초기 상태)\n",
        "\n",
        "5000 /\t32 /\t98.67\t / 98.3199 /\t5\t\t  (셔플 횟수 변화시켰을 때)\n",
        "\n",
        "5000 /\t64 /\t98.47 /\t98.202 /\t5\t\t     (batch size 변화시켰을 때)\n",
        "\t\t\t\t\t\t\n",
        "5000 /\t32 /\t99.2245 /\t98.191 /\t10\t\t(epoch 변화시켰을 때)\n",
        "\t\t\t\t\t\t\n",
        "5000 /\t32 /\t98.67 /\t98.3199 /\t5     \t(Dense 레이어 하나만 있을 때( 출력뉴런의 수는 256))\t       **[두번째로 높은 정확도]**\n",
        "\n",
        "5000 /\t32 /\t98.67 /\t98.342 /\t5\t  (레이어를 하나 추가하였을 때( 출력뉴런의 수는 256, 128))\t**[가장 높은 정확도]**\n",
        "\n",
        "5000 /\t32 /\t98.36 /\t98.18 /\t5\t  (레이어를 두개 추가하였을 때( 출력뉴런의 수는 256, 128,  64))\t\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "셔플 횟수와 batch size, epoch 수와 레이어를 변화시켜가며 가장 높은 정확도를 얻을 때의 값을 알아보았습니다. \n",
        "\n",
        "이제 다른 파라미터는 고정시킨 다음 regularization으로 Dropout(rate)을 주었을 때\n",
        "\n",
        " 정확도에 어떤 영향을 미치는지 알아보겠습니다.\n",
        "\n",
        "regularization으로 Dropout(rate = 0.1)을 주었을 때 (출력뉴런의 수가 256인 Dense 레이어가 하나만 있을때)\n",
        "\n",
        "트레이닝정확도(%)\t/ 테스트정확도(%)\n",
        "\n",
        "98.76  / 98.22\n",
        "\n",
        "regularization으로 Dropout(rate = 0.1)을 주었을 때 (출력뉴런의 수가 256, 128인 Dense 레이어가 두 개 있을때)\n",
        "\n",
        "98.63 / 98.28\n",
        "\n",
        "regularization으로 Dropout(rate = 0.2)을 주었을 때 (출력뉴런의 수가 256, 128인 Dense 레이어가 두 개 있을때)\n",
        "\n",
        "98.68 / 98.25\n",
        "\n",
        "따라서 이 결과를 통해 regularization으로 Dropout을 주었을 때 정확도가 오히려 감소한다는 것을 알 수 있었습니다. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qcyU97-r0ia"
      },
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "# 트레이닝에 필요한 optimizer와 loss function의 종류는 각각 Adam과 crossentropy loss function을 사용하였습니다.\n",
        "# 많은 옵티마이저 중 keras.optimizers.Adam(Adaptive moment estimation)은 기존 RMSprop과 momentum과 다르게 바이어스가 수정된 값으로 변경하는 과정이 포함되어있기 때문에 선택해보았습니다.\n",
        "# 또한 Adam의 경우 α=0.001, β1으로는 0.9, β2로는 0.999, ϵ 으로는 10^-8 값이 가장 좋은 Default값이라고 논문에 명시되어 있고 이 값이 이미 빌트인 되어 있기 때문에 lr(learning rate)을 변경하지 않았습니다.\n",
        "# crossentropy loss function는 두 개 이상의 label class가 있을 때 유용하기 때문에 선택해보았습니다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVrLOvqdr18w"
      },
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "\n",
        "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n",
        "# model의 loss와 accuracy을 측정할 지표를 선택하고 epoch가 진행되는 동안 수집된 측정 지표를 바탕으로 최종 결과를 출력하도록 하였습니다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DheTj3_9r3uM"
      },
      "source": [
        "@tf.function\n",
        "def train_step(images, labels):\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = model(images)\n",
        "    loss = loss_object(labels, predictions)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "  train_loss(loss)\n",
        "  train_accuracy(labels, predictions)\n",
        "  # 자동 미분(주어진 입력 변수에 대한 연산의 그래디언트(gradient)를 계산하는 것)을 위해 tf.GradientTape ap를 사용하였습니다. \n",
        "  # tf.GradientTape는 context 안에서 실행된 모든 연산을 tape에 기록한 다음 후진 방식 자동 미분(reverse mode differentiation)을 사용해 테이프에 기록된 연산의 그래디언트를 계산하게됩니다.\n",
        "  # tf.GradientTape를 이용하여 model을 training하였습니다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krhjOKW6r5lx"
      },
      "source": [
        "@tf.function\n",
        "def test_step(images, labels):\n",
        "  predictions = model(images)\n",
        "  t_loss = loss_object(labels, predictions)\n",
        "\n",
        "  test_loss(t_loss)\n",
        "  test_accuracy(labels, predictions)\n",
        "  # 이 부분은 model을 테스트하기 위한 함수를 정의해주었습니다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqNrydKMr652",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e05625de-1b4e-42a4-d54c-b17986910f5e"
      },
      "source": [
        "EPOCHS = 5\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  for images, labels in train_ds:\n",
        "    train_step(images, labels)\n",
        "\n",
        "  for test_images, test_labels in test_ds:\n",
        "    test_step(test_images, test_labels)\n",
        "\n",
        "  template = '에포크: {}, 손실: {}, 정확도: {}, 테스트 손실: {}, 테스트 정확도: {}'\n",
        "  print (template.format(epoch+1,\n",
        "                         train_loss.result(),\n",
        "                         train_accuracy.result()*100,\n",
        "                         test_loss.result(),\n",
        "                         test_accuracy.result()*100))\n",
        "# epoch는 다른 파라미터들은 고정 시킨 뒤 epoch 값만 변화시켜 10일 때와 5일 때를 비교하였을 때 5일 때가 더 높은 훈련정확도와 테스트정확도를 보여 5로 설정하였습니다."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "에포크: 1, 손실: 0.02198944054543972, 정확도: 99.31242370605469, 테스트 손실: 0.07891853153705597, 테스트 정확도: 98.20726776123047\n",
            "에포크: 2, 손실: 0.020442843437194824, 정확도: 99.36000061035156, 테스트 손실: 0.07955821603536606, 테스트 정확도: 98.23583221435547\n",
            "에포크: 3, 손실: 0.019193487241864204, 정확도: 99.40128326416016, 테스트 손실: 0.08125017583370209, 테스트 정확도: 98.25\n",
            "에포크: 4, 손실: 0.018085462972521782, 정확도: 99.43690490722656, 테스트 손실: 0.08353298902511597, 테스트 정확도: 98.25428771972656\n",
            "에포크: 5, 손실: 0.01724787801504135, 정확도: 99.46521759033203, 테스트 손실: 0.0856085866689682, 테스트 정확도: 98.26533508300781\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQCECx_GlARO"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UlD1X2lloAi"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTVYFtVYr_35"
      },
      "source": [
        "# !mkdir -p saved_model\n",
        "# model.save('saved_model/my_model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqykfSLQieog"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}